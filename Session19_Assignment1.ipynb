{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What are the three stages to build the hypotheses or model in machine learning?\n",
    "\n",
    "Model building\n",
    "Model testing\n",
    "Applying the model\n",
    "\n",
    "### What is the standard approach to supervised learning?\n",
    "\n",
    "The standard approach is to split the dataset into Train and test dataset.\n",
    "\n",
    "### What is Training set and Test set?\n",
    "\n",
    "Training dataset is used to construct a model (As the name inplies, we use this to train our model). Whereas a test data set is used to validate our model. We have to normally re run our model on these datasets multiple times so that we can ensure that we are not over fitting our model.\n",
    "\n",
    "### What is the general principle of an ensemble method and what is bagging and boosting in ensemble method?\n",
    "\n",
    "1) Ensemble method combines the predictions of several models with respect to an algorithm in order to improve robustness over a single model.Ensemble model combines multiple diverse models together and provides an optimized solution on prediction.\n",
    "\n",
    "2) The technique of bagging is used in ensemble to improve the estimation of classification. we create random samples of the training data set (sub sets of training data set). Then, we build a classifier for each sample. Finally, results of these multiple classifiers are combined using average or majority voting. Bagging helps to reduce the variance error.\n",
    "\n",
    "3) Boosting provides sequential learning of the predictors. The first predictor is learned on the whole data set, while the following are learnt on the training set based on the performance of the previous one. It starts by classifying original data set and giving equal weights to each observation. Boosting provides better accuracy than bagging.\n",
    "\n",
    "### How can you avoid overfitting?\n",
    "\n",
    "1) Cross-Validation : One sample as in-time validation and rest for training the model. High fold cross validation is used for lower variance.\n",
    "\n",
    "2) Early Stopping : Limits the number of iterations.\n",
    "\n",
    "3) Pruning : Removes the fields which adds little value for prediction.\n",
    "\n",
    "4) Regularization :  It tries to push the coefficients for many variables to zero and hence reduce cost term.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
